---
title: "Lab 4"
subtitle: ""
author: "Attila Lazar"
date: "04.11.2020"
output: pdf_document
---

## data

We load the dataset and split train and test datasets

```{r, echo=TRUE}
load("data/dat.RData")
data <- d
set.seed(1234)
n <- nrow(data)
train <- sample(1:n, round(n*2/3))
test <- (1:n) [-train]

```


# 1)

## a)

We train a LS model on the training whole dataset

```{r, echo=TRUE}

model1 <- lm(y~., data, subset=train) 
#summary (model1)

```

for calculating trimmed MSE we define following functions

```{r, echo=TRUE}
rtmean <- function(x,trim = 0) {
  x <- sort(x)
  v <- x[1:floor(length(x)*(1-trim))]
  mean(v)
}

mse <- function(y.true,y.pred, trim=0){
  return(rtmean((y.true - y.pred)^2, trim =trim))
}
```

we calculate MSE on the test dataset

```{r, echo=TRUE}
mse(data[test, 'y'], predict(model1, data[test,]))

```

Then the 10% trimmed MSE on the test dataset

```{r, echo=TRUE}
mse(data[test, 'y'], predict(model1, data[test,]), trim=0.1)
```

The trimmed MSE is - as expected - much better. R warns about the model fit beeing rank-deficient because we do not have full rank in our input matrix

We plot the predicted values agaist the actual y values

```{r, echo=TRUE}
plot(data[test, 'y'], predict(model1, data[test,]), xlab='y' ,ylab='y-hat', main="validation")
abline(c(0,1))
```

We see there are a few outliers with bad predictions

# 2)

## a)

We train pcr regression models with up to 100 components with the train dataset

```{r, echo=TRUE}
library(pls)

ncomp <- 100
model2 <- pcr(y~., ncomp=ncomp, data=data, subset=train, scale=TRUE, validation="CV", segments=10,  segment.type="random")
```

## b)

```{r, echo=TRUE}
plot(model2, plottype="validation", val.type="MSEP")
```
The plot does not look like expected, the MSEP increases and reaches very high numbers. This is probably because of outliers which disturb the fitting process. We cannot use this plot to select the optimal number of components.

## c)

Now we look on the predictions on the train data

```{r, echo=TRUE}
selcomp <- 17
predplot(model2, line=TRUE, ncomp=selcomp, labels=rownames(data[train,]))

```

There is a very big prediction error for one datapoint. To better see the result we replot restricting the y axix 


```{r, echo=TRUE}
plot(model2, ncomp=selcomp, line=TRUE, ylim=c(-5,5))

```

## d)

To better deal with outliers we recreate the plot from 2b using 10 % trimmed MSE. We use the test dataset for the MSE calculations

```{r, echo=TRUE}
res <- vector(length = ncomp)
for (i in 1:ncomp) {
  res[i] <- mse(data[test,'y'], predict(model2, data[test,], ncomp=i), trim=0.1)
}
plot(res, type='s', xlab="number of components", ylab="TMSE", main="10% trimmed MSE values")
```

Here we see a sharp drop on MSE to around 20 components. After that the MSE only improves slightly. We choose 20 as optimal number of compoents and calculate the trimmed MSE again

```{r, echo=TRUE}
selcomp <- 20
mse(data[test, 'y'], predict(model2, newdata=data[test,], ncomp=selcomp), trim=0.1)

```

We plot the predictions 

```{r, echo=TRUE}
plot(data[test, 'y'], predict(model2, data[test,], ncomp=selcomp), xlab='y' ,ylab='y-hat', main=paste0("validation with components = ", selcomp))
abline(c(0,1))

```

# 3)

## a)

We use the same argumenst then in 2) to train a Partial Least Squares model with up to 100 components

```{r, echo=TRUE}
ncomp <- 100
model3 <- plsr(y~., ncomp=ncomp, data=data, subset=train, scale=TRUE, validation="CV", segments=10,  segment.type="random")

```

## b)

```{r, echo=TRUE}
plot(model3, plottype="validation", val.type="MSEP")
```

Again we see a simular plot then in 2) which is not usable to select the optimal number of components.

## c)

We plot the prediction with 20 compoents, to get an interpretable plot we limit the y axis

```{r, echo=TRUE}
predplot(model3, line=TRUE, ncomp=20, ylim=c(-4, 4))

```

## d)

We recalculate 10% timmed mse-s with the test dataset for up to 100 components
```{r, echo=TRUE}

res <- vector(length = ncomp)
for (i in 1:ncomp) {
  res[i] <- mse(data[test,'y'], predict(model3, data[test,], ncomp=i), trim=0.1)
}
plot(res, type='s', xlab="number of components", ylab="TMSE", main="10% trimmed MSE values")

```

We see that there is a clear choise for the best number of components

```{r, echo=TRUE}
selcomp <- which.min(res)
selcomp
```
with trimmed MSE
```{r, echo=TRUE}
min(res)
```

```{r, echo=TRUE}
plot(data[test, 'y'], predict(model3, data[test,], ncomp=selcomp), xlab='y' ,ylab='y-hat', main=paste0("validation with components = ", selcomp))
abline(c(0,1))
```

## e)

We replot the plot from 3b) using 10 % trimmed MSE

```{r, echo=TRUE}
res <- vector(length = ncomp)
for (i in 1:ncomp) {
  res[i] <- mse(data[train,'y'], model3$validation$pred[,1,i], trim=0.1)
}
plot(res, type='s', xlab="number of components", ylab="TMSE", main="10% trimmed MSE values")
```

The MSE dropps sharply till 3 and rises again after about 10 components

the optimal nr of components seems to be around 3:

with the 10% trimmed MSE of
```{r, echo=TRUE}
res[3]
```

The result with 3 components is slightly worse than with 6 components selected in 3d)

# 4)

We select 20 components to creat ore pcr model. We scale the input data, then calculate the regression coeficients using the scores from princomp. Then we plot our predictions

```{r, echo=TRUE}
selcomp = 20
data.s <- scale(data)
X <- data.s[train, 2:393]
pc <- princomp(X)
Z <- pc$scores[,1:selcomp]
y <- data.s[train, 'y']
betaH <- solve(t(Z)%*%Z)%*%crossprod(Z,y)
yH <- Z %*% betaH
plot(y, yH, main="validation with training data")
abline(c(0,1))

```

```{r, echo=TRUE}
mse(y, yH, trim=0.1)

```

We repeat with the test dataset

```{r, echo=TRUE}
Xt <- data.s[test, 2:393]
yt <- data.s[test, 'y']
Zt <- Xt %*% pc$loadings[,1:selcomp]
yH <- Zt %*% betaH
plot(yt, yH, main="validation with test data")
abline(c(0,1))

```

```{r, echo=TRUE}
mse(yt, yH, trim=0.1)
```

The MSE is very simular to the MSE from 2d) 


